{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/octoopt/anaconda3/envs/hcmc/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/octoopt/anaconda3/envs/hcmc/lib/python3.10/site-packages/fairscale/experimental/nn/offload.py:19: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  return torch.cuda.amp.custom_fwd(orig_func)  # type: ignore\n",
      "/home/octoopt/anaconda3/envs/hcmc/lib/python3.10/site-packages/fairscale/experimental/nn/offload.py:30: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  return torch.cuda.amp.custom_bwd(orig_func)  # type: ignore\n"
     ]
    }
   ],
   "source": [
    "from components.fuzzymatching import FuzzyMatchingFactory\n",
    "from core.config import Environment, Config\n",
    "\n",
    "\n",
    "matching_tool_config = {'csv_path': './backend/db/keyframes.csv', \n",
    "                        'env_dir': Environment()}\n",
    "ocr_matcher = FuzzyMatchingFactory.produce('rapidwuzzy', **matching_tool_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<components.llms.gemini.GeminiAgent at 0x79ba8f0598a0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from components.llms import AgentFactory\n",
    "from components.llms.prompts import EXTRACT_KEYWORDS\n",
    "from schema.llm_response import Keyword\n",
    "\n",
    "import os \n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "llm_config = {'api_key': GOOGLE_API_KEY, \n",
    "              'response_setting': {\n",
    "                  \"response_mime_type\":'application/json', \n",
    "                  \"response_schema\": list[Keyword]\n",
    "              }}\n",
    "llm_agent = AgentFactory.produce(provider='gemini', \n",
    "                                 **llm_config)\n",
    "llm_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Đoạn giới thiệu về lễ hội Việt - Nhật. Trong lễ hội có các phân cảnh những chiếc lồng đèn kiểu Nhật cùng những chiếc dù Wagasa. Phân đoạn giữa có hình ảnh của chú mèo máy Doraemon khổng lồ và có những người xung quanh chụp ảnh với nó. Phân đoạn sau đó có hình ảnh một ban nhạc Nhật chơi các nhạc cụ truyền thống trên sân khấu. Xuyên suốt đoạn giới thiệu là một số đoạn phỏng vấn những người tham gia lễ hội. Hỏi có tổng cộng bao nhiêu người khác nhau được phỏng vấn trong đoạn giới thiệu trên?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Việt - Nhật Festival',\n",
       " 'Japanese lanterns',\n",
       " 'Wagasa umbrellas',\n",
       " 'Doraemon',\n",
       " 'Japanese music',\n",
       " 'traditional instruments',\n",
       " 'festival attendees']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "kw_v3 = llm_agent.run(EXTRACT_KEYWORDS + '\\n' + query)\n",
    "kw_v3 = json.loads(kw_v3)\n",
    "kw_v3 = [d['keyword'] for d in kw_v3]\n",
    "kw_v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70\n",
      "57\n",
      "['L24_V032-16779.webp', 'L01_V023-16435.webp', 'L24_V009-11008.webp', 'L24_V002-03835.webp', 'L22_V016-32655.webp', 'L09_V014-31190.webp', 'L24_V043-10716.webp', 'L10_V024-00419.webp', 'L09_V010-00657.webp', 'L20_V016-00007.webp', 'L01_V031-21436.webp', 'L24_V024-02104.webp', 'L21_V027-12655.webp', 'L20_V013-12582.webp', 'L24_V030-17737.webp', 'L24_V031-07816.webp', 'L24_V004-19383.webp', 'L24_V002-05810.webp', 'L18_V008-00318.webp', 'L10_V008-29727.webp', 'L24_V028-12507.webp', 'L24_V013-09371.webp', 'L24_V031-07865.webp', 'L24_V029-15532.webp', 'L24_V037-15045.webp', 'L20_V019-30498.webp', 'L24_V006-08591.webp', 'L24_V014-03893.webp', 'L02_V030-15045.webp', 'L07_V013-00529.webp', 'L23_V021-11160.webp', 'L13_V022-20516.webp', 'L24_V011-02194.webp', 'L24_V032-10966.webp', 'L24_V009-05306.webp', 'L24_V004-14444.webp', 'L19_V024-31339.webp', 'L24_V014-08476.webp', 'L24_V008-02415.webp', 'L20_V019-24400.webp', 'L05_V024-18145.webp', 'L13_V024-01560.webp', 'L20_V017-33624.webp', 'L24_V026-13456.webp', 'L10_V008-00034.webp', 'L24_V007-07244.webp', 'L19_V016-20743.webp', 'L11_V006-12142.webp', 'L17_V009-00042.webp', 'L24_V020-08273.webp', 'L24_V043-10213.webp', 'L24_V031-01814.webp', 'L24_V018-00000.webp', 'L20_V002-08175.webp', 'L19_V024-29772.webp', 'L21_V013-31966.webp', 'L24_V007-09780.webp']\n"
     ]
    }
   ],
   "source": [
    "matching_paths_v3 = []\n",
    "\n",
    "for kw in kw_v3: \n",
    "    result = ocr_matcher.run(kw)\n",
    "    img_paths = ocr_matcher.get_image_paths(result)\n",
    "    matching_paths_v3 += img_paths\n",
    "\n",
    "print(len(matching_paths_v3))\n",
    "matching_paths_v3 = list(set(matching_paths_v3))\n",
    "print(len(matching_paths_v3))\n",
    "print(matching_paths_v3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "env_dir = Environment()\n",
    "with open(os.path.join(env_dir.root, env_dir.db_root, env_dir.vid_url), 'r') as f:\n",
    "    vid_url = json.load(f)\n",
    "\n",
    "with open(os.path.join(env_dir.root, env_dir.db_root, env_dir.url_fps), 'r') as f:\n",
    "    url_fps = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_by_ocr(query:str, top_k, matching_tool, llm, vid_url:dict, url_fps:dict): \n",
    "    \"\"\"\n",
    "    Searching by keywords using OCR.\n",
    "    \"\"\"\n",
    "\n",
    "    # Pick up keywords from the original query\n",
    "    extract_kw_query = EXTRACT_KEYWORDS + \"\\n\" + query\n",
    "    retries = 3\n",
    "    try: \n",
    "        \n",
    "        keywords = llm.run(extract_kw_query)\n",
    "        # print(keywords)\n",
    "        # print(type(keywords))\n",
    "        if isinstance(keywords, str): \n",
    "            while retries >= 0: \n",
    "                # Normally, it executes 2 times and break.\n",
    "                keywords = json.loads(keywords)\n",
    "                # print(type(keywords))\n",
    "                if type(keywords) == dict or type(keywords) == list: \n",
    "                    break\n",
    "                retries -= 1\n",
    "        keywords = [d['keyword'] for d in keywords]\n",
    "        # print(keywords)\n",
    "\n",
    "    except Exception as e: \n",
    "        raise json.JSONDecodeError(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid_urls = []\n",
    "# embed_urls = []\n",
    "frames = []\n",
    "# image_paths = [image_path.split('/')[-1] for image_path in matching_paths]\n",
    "for img_id in matching_paths_v3: \n",
    "    vid_id = img_id.split('.')[0]\n",
    "    vid_name, frame = vid_id.split('-')\n",
    "    url = vid_url[vid_name] + '&t=' + str(int(int(frame)/url_fps[vid_url[vid_name]]))\n",
    "    # embed_url = vid_url[vid_name].replace('watch?v=', 'embed/') # TODO: make this execuate from frontend\n",
    "    vid_urls.append(url)\n",
    "    # embed_urls.append(embed_url)\n",
    "    frames.append(frame)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "results = search_by_ocr(query=query, \n",
    "                        top_k=10, \n",
    "                        matching_tool=ocr_matcher, \n",
    "                        llm=llm_agent, \n",
    "                        vid_url=vid_url, \n",
    "                        url_fps=url_fps)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<components.llms.gemini.GeminiAgent at 0x7844a92cbc70>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from components.llms import AgentFactory\n",
    "from schema.llm_response import RefineQuery\n",
    "\n",
    "import os \n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "llm_config = {'api_key': os.getenv(\"GOOGLE_API_KEY\"), \n",
    "              'response_setting': {\n",
    "                  \"response_mime_type\":'application/json', \n",
    "                  \"response_schema\": RefineQuery\n",
    "              }}\n",
    "refine_agent = AgentFactory.produce(provider='gemini', \n",
    "                                 **llm_config)\n",
    "refine_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_REWRITE = \"\"\"Provide a concise and specific search query for an event retrieval engine to find relevant events based on the following prompt. Remember to keep the language and intention of the original prompt.\n",
    "\n",
    "Prompt: {prompt}\n",
    "\n",
    "Refine Query: \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "HYPOTHETICAL_REWRITE = \"\"\"Act as a prompt engineer skilled at refining prompts for an event retrieval engine. Your task is to refine the following prompt to optimize results.  Follow these steps:\n",
    "\n",
    "1. **Keyword Extraction:** Identify the semantically relevant keywords within the input prompt.  Prioritize keywords that directly relate to events, locations, dates, or key figures.\n",
    "\n",
    "2. **Contextual Analysis:** Analyze the keywords in relation to the overall topic of the prompt.  Infer the implicit meanings and potential relationships between the keywords.  Consider what specific information the retrieval engine might need to find relevant events.\n",
    "\n",
    "3. **Refined Prompt Generation:**  Rewrite the input prompt based on your keyword analysis and contextual understanding.  The refined prompt should be a concise and accurate query that explicitly targets the desired information.\n",
    "\n",
    "Remember to keep the language and intention of the original prompt.\n",
    "\n",
    "Prompt: {prompt}\n",
    "\n",
    "Refined Query:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tìm số lượng người được phỏng vấn trong đoạn giới thiệu lễ hội Việt - Nhật, tập trung vào các phân cảnh có lồng đèn Nhật, dù Wagasa, mèo máy Doraemon khổng lồ, và ban nhạc Nhật chơi nhạc cụ truyền thống.'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = refine_agent.run(HYPOTHETICAL_REWRITE.format(prompt=query))\n",
    "result = json.loads(result)\n",
    "result['refine_response']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'author': '60 Giây Official',\n",
       " 'channel_id': 'UCRjzfa1E0gA50lvDQipbDMg',\n",
       " 'channel_url': 'https://www.youtube.com/channel/UCRjzfa1E0gA50lvDQipbDMg',\n",
       " 'description': '60 Giây Chiều - Ngày 15/06/2024 - HTV Tin Tức Mới Nhất 2024\\n► Đăng ký KÊNH để xem Tin Tức Mới Nhất: https://bit.ly/2HoUna4\\nKênh Tin Tức Thời Sự 60 Giây Là Kênh Tổng Hợp Tin Tức - Sự Kiện - Giải trí Nhanh Nhất Việt Nam.\\n\\n©️ Bản quyền Tin Tức thuộc HTV - Đài Truyền hình TP.HCM\\n©️ The copyright of this video belongs to HTV - Ho Chi Minh City Television\\n#TintucthoisuVietnam\\n#HTVTintuc #HTVnews #HTV60s #60Giay #60s\\n------------\\nXem TV online tại Truyền hình HTVC:\\n✅ Web / Wap mobile :\\n► https://hplus.com.vn\\n► https://htvc.com.vn/\\n► https://htvc.tv/\\n✅ App mobile/TV HTVC :\\n► IOS: https://goo.gl/Dih3DB\\n► Android: https://goo.gl/XGBzxg\\n► Smart TV /STB : Tải HTVC for Android TV\\n.\\n✅ Theo dõi HTVC trên Mạng xã hội :\\n- Facebook Show : https://www.facebook.com/HPlusOfficial\\n- Instagram Show : https://www.instagram.com/htvc_truyen_hinh_internet/\\n- Lotus Show : https://lotus.vn/w/profile/18444255300272761.htm\\n- Tiktok News : https://www.tiktok.com/@htvc.tintuc\\n- Tiktok Phim : https://www.tiktok.com/@htvc.phimtruyen\\n- Tiktok Show : https://www.tiktok.com/@htvc.truyenhinh\\n- Youtube Phim : https://www.youtube.com/c/HplusVn\\n- Youtube Phim : https://www.youtube.com/c/HTVCPhim\\n- Youtube News : https://www.youtube.com/c/HTV60s',\n",
       " 'keywords': ['HTV Tin tức',\n",
       "  'HTV News',\n",
       "  'chuong trinh 60 giay',\n",
       "  'chuong trinh 60s',\n",
       "  'ban tin 60 giay',\n",
       "  'ban tin 60s',\n",
       "  '60 giay',\n",
       "  '60s',\n",
       "  '60 giay hom nay',\n",
       "  'Tin tức 60 giây',\n",
       "  'TIN TUC 60 GIAY',\n",
       "  'TIN TỨC 60 GI Y',\n",
       "  'tin tuc 60 giay',\n",
       "  'tin tức',\n",
       "  '60 giây',\n",
       "  'Tin Tức',\n",
       "  'TIN TUC',\n",
       "  '60 GIAY',\n",
       "  'Tin Tức Mới',\n",
       "  'Tin Tức Mới Nhất',\n",
       "  '60 Giây',\n",
       "  'HTV Tin Tức',\n",
       "  'HTV news',\n",
       "  'Xem tin tức mới nhất',\n",
       "  'Xem tin tức',\n",
       "  'Hôm nay xem gì',\n",
       "  '60 giây Sáng',\n",
       "  '60 giây chiều',\n",
       "  'Bản tin 60s',\n",
       "  'Tin tức thời sự việt nam',\n",
       "  'Tin tuc thoi su Viet nam'],\n",
       " 'length': 927,\n",
       " 'publish_date': '16/06/2024',\n",
       " 'thumbnail_url': 'https://i.ytimg.com/vi/Zo1FBc4PGCM/sddefault.jpg?v=666e77b4',\n",
       " 'title': '60 Giây Chiều - Ngày 15062024 - HTV Tin Tức Mới Nhất 2024',\n",
       " 'watch_url': 'https://youtube.com/watch?v=Zo1FBc4PGCM'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "import json\n",
    "\n",
    "def get_video_metadata(vid_idx, media_dir): \n",
    "    vid_name = '.'.join([vid_idx, 'json']) # File is in .json format\n",
    "    vid_metadata = json.loads(open(os.path.join(media_dir, vid_name), 'r').read())\n",
    "    return vid_metadata\n",
    "\n",
    "\n",
    "vid_idx = 'L18_V015'\n",
    "media_dir = './db/media-info'\n",
    "\n",
    "get_video_metadata(vid_idx=vid_idx, \n",
    "                   media_dir=media_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hcmc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
